---
title: "Untitled"
output: html_document
---

```{r}
library(htmltab)
library(data.table)
library(RPostgreSQL)

##This dataset is the count of COVID-19 cases per county in Tennessee, updated each day at 2PM
library(readxl)
library(httr)
link = "https://www.tn.gov/content/dam/tn/health/documents/cedep/novel-coronavirus/datasets/Public-Dataset-County-New.XLSX"
GET(link, write_disk(tf <- tempfile(fileext = ".XLSX")))
countytable <- read_excel(tf)


#This dataset is the projection of hospital resources necessary for the COVID-19 epidemic in the Tennessee area. 
projection <- fread("curl https://ihmecovid19storage.blob.core.windows.net/latest/ihme-covid19.zip | tar -xf- --to-stdout *Hospitalization_all_locs.csv")
projection = projection[which(projection$location_name == 'Tennessee'),]

#Covid 19 Positive numbers from John Hopkins
usadat_confirmed_time = read.csv("https://github.com/CSSEGISandData/COVID-19/raw/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv")
tndata = usadat_confirmed_time[which(usadat_confirmed_time$Province_State == 'Tennessee'),]
hamdata = tndata[which(tndata$Admin2 == 'Hamilton'),]

write.csv(projection, "../Data/OutbreakProjections/IHMEProjections.csv")
write.csv(tndata, "../Data/CaseData/TNCaseData.csv")
write.csv(usadat_confirmed_time, "../Data/CaseData/AllUSCaseData.csv")
write.csv(countytable, "../Data/CaseData/CountyTests.csv")

remove(link, tf)
```

```{r}
library(reticulate)
# use_python("/Users/peteway/.local/share/virtualenvs/COVID19-Analysis-LNCuW-Do/bin/python", required = TRUE)
use_virtualenv("/Users/peteway/.local/share/virtualenvs/COVID19-Analysis-LNCuW-Do", required = TRUE)
py_config()
```

```{python}
import os
import datetime 
import pandas 
from arcgis.gis import GIS
from arcgis.features import FeatureLayerCollection

##Login to GIS
gis = GIS()
safegraphid = "6ac3ff66afb54f35b66cbad9f41f127c"

test = gis.content.get(id)
layer = FeatureLayerCollection(test.url)

##Pulls the individual layer out of the collection
layer = layer.layers
layer = layer[0]

##Pulls the entire set of data within that layer
query_result1 = layer.query()

##Converts the query results into a dataframe. 
frame = query_result1.sdf
##Date format = 2020-04-06 15:32:29.533999919, so drop the millisec section.
# frame[['last_updated']] = datetime.datetime.strptime((str(max(frame.last_updated)).split(".")[0]), "%Y-%m-%d %H:%M:%S")
print(frame.last_updated[0])
print(frame.columns)
frame = frame[frame['state_name']=='Tennessee']

frame.to_csv("../Data/UnacastSocialDistancing.csv", index=False)

```



```{r}
library(tidyverse)

specbreakdown <- read.csv("https://docs.google.com/spreadsheets/d/e/2PACX-1vQi60Tqg5FruuwAsJBXYvKJe0badlLsnS0k7B36hARrIrI8FMZOEVfTgQFLVsudSmUs6WZv6RYsKB6I/pub?gid=1081269126&single=true&output=csv")
# divisions = specbreakdown %>% group_by(Category, Cat_Detail)
daily <- read.csv("https://docs.google.com/spreadsheets/d/e/2PACX-1vQi60Tqg5FruuwAsJBXYvKJe0badlLsnS0k7B36hARrIrI8FMZOEVfTgQFLVsudSmUs6WZv6RYsKB6I/pub?gid=1242898529&single=true&output=csv")

divisions<-split(specbreakdown, specbreakdown$CATEGORY)
Ethnicity = divisions$Ethnicity
Race = divisions$Race
Sex = divisions$Sex
remove(divisions, specbreakdown)

age <- read.csv("https://docs.google.com/spreadsheets/d/e/2PACX-1vQi60Tqg5FruuwAsJBXYvKJe0badlLsnS0k7B36hARrIrI8FMZOEVfTgQFLVsudSmUs6WZv6RYsKB6I/pub?gid=263818242&single=true&output=csv")

zipcases = read.csv("https://docs.google.com/spreadsheets/d/e/2PACX-1vQi60Tqg5FruuwAsJBXYvKJe0badlLsnS0k7B36hARrIrI8FMZOEVfTgQFLVsudSmUs6WZv6RYsKB6I/pub?gid=96499078&single=true&output=csv")

write_csv(zipcases, "/Users/peteway/Documents/GitHub/COVID19-Analysis/Data/CaseData/ZipData.csv")
write_csv(Ethnicity, "/Users/peteway/Documents/GitHub/COVID19-Analysis/Data/CaseData/EthData.csv")
write_csv(Race, "/Users/peteway/Documents/GitHub/COVID19-Analysis/Data/CaseData/RaceData.csv")
write_csv(Sex, "/Users/peteway/Documents/GitHub/COVID19-Analysis/Data/CaseData/SexData.csv")
write_csv(age, "/Users/peteway/Documents/GitHub/COVID19-Analysis/Data/CaseData/AgeData.csv")
write_csv(daily, "/Users/peteway/Documents/GitHub/COVID19-Analysis/Data/CaseData/DailyData.csv")
```

```{r}
path = "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/"

yesterdate = format(Sys.Date()-1,"%Y-%m-%d")
dates = format(seq(as.Date("2020-01-22"), as.Date(yesterdate), by="days"), format="%m-%d-%Y")

pathdates = vector("character", length = length(dates))
num = 1
for (i in dates){
  pathdates[num] = paste(path, i, ".csv", sep="")
  num = num+1
}


library(tidyverse)
library(data.table)
allmatrix <- lapply(pathdates, function(i){
  read.csv(i)})


keep = c("Province.State", "Country.Region", "Last.Update","Confirmed","Deaths","Recovered", "Admin2")

lapply(allmatrix, function(x) x[(names(x) %in% keep)])

total = data.frame(matrix(ncol = length(keep), nrow = 0))
for(i in allmatrix)
{
  colnames(i) = gsub("_",".",colnames(i))
  if (!'Admin2' %in% colnames(i))
  {
    i$Admin2 = 0
  }
  i = i[,(names(i) %in% keep)]
  print(length(colnames(i)))
  total = rbind(total, i)
}
total[is.na(total)] <- 0


names(total)[names(total) == 'Last.Update'] <- 'Date'
names(total)[names(total) == 'Admin2'] <- 'County.Other'


multidate <- function(data, formats){
    a<-list()
    for(i in 1:length(formats)){
        a[[i]]<- as.Date(data,format=formats[i])
        a[[1]][!is.na(a[[i]])]<-a[[i]][!is.na(a[[i]])]
        }
    a[[1]]
    }


total$Date <- multidate(total$Date, c("%m/%d/%Y","%m/%d/%y","%Y-%m-%d"))


write_csv(total, "/Users/peteway/Documents/GitHub/COVID19-Analysis/Data/GlobalData.csv")

remove(dates, i, num, path, pathdates, yesterdate, keep, multidate, allmatrix)
```




```{r}
traffic = read.csv("https://internal.chattadata.org/api/views/fpgh-69ti/rows.csv?accessType=DOWNLOAD")

length(unique(traffic$geom))
```